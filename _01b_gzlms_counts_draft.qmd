# Modelling counts

```{r}
library(tidyverse)
source("functions/helpers.R")
```

In the previous section, we looked at the consequences of pretending a bound asymmetrically distribution is unbound and symmetrical. In this tutorial, we're going to discuss what happens if we assume that a distribution is continuous when, in fact, it is not.

Every model that we fit makes one fundamental assumption that more often than not won't be highlighted on any diagnostic plots. It's the assumption about the level of measurement of our variable. For example, logistic models assume that the outcome variable is a **categorical binary** variable, ordinal models assume the outcome is **ordinal**, Gaussian and Gamma models assume that it is **continuous**. The reason why software often doesn't provide an immediately obvious way to check that this assumption is met is that it is out responsibility as the researcher to ensure the way we're operationalising a variable is suitable for the kind of model we want to later fit.

Another level of measurement is **counts**. For example,

-   How many cups of coffee does an average lecturer drink per day?

-   How many children are there in a typical household?

-   How many goals are typical in a football game?

-   How many short-form videos does an average grad student scroll through per day when procrastinating work?

Even though counts are discrete, they are another victim of the GLM tyranny, more often than not modelled as unbound continuous variables. The consequences of assuming a continuous level of measurement when the variable is measured in counts vary in severity, depending on the context. For example, if we say that an average lecturer drinks 3.5 cups of coffee per day, it implies that they either make half a cup of coffee (which is silly), or they make four and then pour out half of one (which is unhinged). However, if we say that a typical household consists of two parents, one dog, one cat, and 2.4 children, things suddenly take a dark turn.

In this tutorial, we're going to look into ways of modelling count variables more sensibly. We'll explore the following types of models:

-   Poisson models

-   Negative binomial models

-   Quasi-poisson models

-   Zero-inflated models

## Scenario

> A university lecturer wishes to understand the predictors of undergraduate student attendance in lectures. They record the number of lectures the students attended per 11-week term (with one lecture per week). For predictors, they considers:
>
> -   Year of study (first, second, or third)
>
> -   How many lecture recordings they accessed
>
> -   Average grade on the module
>
> The lecturer wants to include all predictors in the model. They only make one hypothesis based on prior experience:
>
> H~1~: First year students will be more likely to attend lectures compared to second and third year students.
>
> The inclusion of the remaining predictors is exploratory.

```{r eval=FALSE}
set.seed(11)
# 7 8 

n = 3000
        b0 = 3.1
        b1 = -0.7
        b2 = 0.02
        b3 = 0.01
        
        theta = 5
        
        x1 <-    rnorm(n) |>   squish(1, 3)        # year
        x2 <-    rnorm(n) |> squish(0, 11)         # record
        x3 <-    rnorm(n)|> squish(0, 100)         # grade
        
        linear_response = b0 + b1*x1 + b2*x2 + b3*x3 
        exp_response = exp(linear_response) 
        
        y <- rqpois(n = n, 
                    mu = exp_response, 
                    theta = theta) |> squish(0, 11) |> as.integer()
        

        df <- tibble::tibble(
          y = y, 
          x1 = cut_interval(x1, 3) |> factor(labels = c("Year 1", "Year 2", "Year 3")), 
          x2 = x2, 
          x3 = x3
        )
        
        sample_df <- df |> dplyr::slice_sample(n = 584) #375
        
        sample_df[1:150, ] <- sample_df[1:150, ] |> 
          dplyr::mutate(
            y = ifelse(x1 %in% c("Year 3", "Year 2"), 0, x1)
          )
        
        
        sample_df <- sample_df |> 
          dplyr::mutate(
            student_id = sample(x = 20000:30000, size = 584, replace = FALSE)
          ) |> 
          dplyr::slice_sample(n = 584, replace = FALSE) |> 
          dplyr::transmute(
            student_id, n_lectures = y, year = x1, n_record = round(x2, 0), overall_grade = round(x3, 2)
          )
        
        write.csv(sample_df, "data/attendance_data.csv", row.names = FALSE)
        
        
```

```{r}
attend_tib <- readr::read_csv("data/attendance_data.csv")

attend_tib <- attend_tib |> 
  dplyr::mutate(
    year = factor(year)
  )
```

```{r}
describe_distribution(attend_tib, include_factors = TRUE)
```

```{r}
ggplot2::ggplot(data = attend_tib, aes(x = year, y = n_lectures)) + 
  geom_point(position = position_jitter(width = 0.1), alpha = 0.2, colour = "yellowgreen") + 
  stat_summary(colour = "steelblue") + 
  theme_light()
```

```{r}
ggplot2::ggplot(data = attend_tib, aes(x = n_lectures)) + 
  geom_histogram(fill = "yellowgreen", alpha = 0.4) +
  geom_line(stat = "count") +
  geom_point(size = 2, stat = "count") + 
  scale_x_continuous(breaks = seq(0, 11, 1)) + 
  theme_light()
```

## Poisson model

```{r}
attend_poiss <- glm(n_lectures ~ n_record + year + overall_grade, data = attend_tib, family = poisson(link = "log"))

attend_poiss |> check_model()

attend_poiss |> check_overdispersion()

```

## Negative binomial

```{r}
attend_nb <- MASS::glm.nb(n_lectures ~ n_record + year + overall_grade, data = attend_tib)

attend_nb |> check_model()

attend_nb |> performance()
```

## Quasi-poisson

why not gamma - because 0

```{r}
attend_qpoiss <- glm(n_lectures ~ n_record + year + overall_grade, data = attend_tib, family = "quasipoisson")

attend_qpoiss |> check_model()

attend_qpoiss |> performance()

attend_qpoiss |> model_parameters(exponentiate = TRUE)

predict(
  attend_qpoiss, 
  newdata = tibble::tibble(
    n_record = 5, 
    overall_grade = 70, 
    year = factor("Year 1", levels = c("Year 1", "Year 2", "Year 3"))
  )
) |> 
  exp() |> 
  as.integer()
```

## Zero-inflated models

this is where our context knowledge becomes important - if there is another process modelling the zeros,

```{r}
check_zeroinflation(attend_nb)
check_zeroinflation(attend_qpoiss)
```

```{r}
zero_inf_mod <- pscl::zeroinfl(n_lectures ~ n_record + year  + overall_grade, data = sample_df, dist = "poisson")

```

```{r}
zero_inf_mod |> model_parameters(exponentiate = TRUE)
```

```{r}
zero_inf_mod |> model_parameters(exponentiate = TRUE, bootstrap = TRUE, component = "zi")
```
